{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "single-associate",
   "metadata": {},
   "source": [
    "# 01. Preprocessing Street View Housing Numbers (SVHN) Dataset\n",
    "\n",
    "### Purpose:\n",
    "Convert the annotations provided with the SVHN dataset to the Darknet TXT format.\n",
    "\n",
    "### Before Running Notebook:\n",
    "1. Download train.tar.gz and test.tar.gz from [here](http://ufldl.stanford.edu/housenumbers/).\n",
    "1. Extract the files into the Data folder at the top level of this repository.\n",
    "1. The relative path from this notebook to the extracted train and test files must be assigned to the path variable in the final two cells.\n",
    "1. The `digitStruct.mat` file must be included in the same directory as the images that it describes.\n",
    "\n",
    "### Details:\n",
    "The annotations for the SVHN dataset are provided as an h5py formatted file named `digitStruct.mat`.  There is one file for train and one for test.  In this project, I will be using Darknet to train custom Yolo models with this dataset, and Darknet requires annotations to be separated into one text file per image.  \n",
    "\n",
    "More information about Darknet annotation format can be found [here](https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hydraulic-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-argument",
   "metadata": {},
   "source": [
    "## Defining Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "progressive-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_name(f, idx=0):\n",
    "    \"\"\"\n",
    "    Get the name of an image given it's index.\n",
    "    Adapted from https://www.vitaarca.net/post/tech/access_svhn_data_in_python/\n",
    "\n",
    "    Args\n",
    "        f: digitStruct.mat h5py file\n",
    "        idx: index of the image\n",
    "        \n",
    "    Returns:\n",
    "        image name as a string\n",
    "    \"\"\"\n",
    "    names = f['digitStruct/name']\n",
    "    img_name = ''.join(map(chr, f[names[idx][0]][()].flatten()))\n",
    "    return(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swiss-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_boxes(f, idx=0):\n",
    "    \"\"\"\n",
    "    Get the 'height', 'left', 'top', 'width', 'label' of bounding boxes of an image\n",
    "    Adapted from https://www.vitaarca.net/post/tech/access_svhn_data_in_python/\n",
    "\n",
    "    Args\n",
    "        f: digitStruct.mat h5py file\n",
    "        idx: index of the image\n",
    "        \n",
    "    Returns:\n",
    "        dictionary of bounding box values as integers\n",
    "    \"\"\"\n",
    "    bboxs = f['digitStruct/bbox']\n",
    "    box = f[bboxs[idx][0]]\n",
    "    meta = { key : [] for key in box.keys()}\n",
    "\n",
    "    for key in box.keys():\n",
    "        if box[key].shape[0] == 1:\n",
    "            meta[key].append(int(box[key][0][0]))\n",
    "        else:\n",
    "            for i in range(box[key].shape[0]):\n",
    "                meta[key].append(int(f[box[key][i][0]][()].item()))\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crucial-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annot_file(f, path, idx=0):\n",
    "    \"\"\"\n",
    "    Create a single Darknet TXT annotation file for an image.\n",
    "    Writes to file <image name>.txt in same directory as image.\n",
    "\n",
    "    Args\n",
    "        f: digitStruct.mat h5py file\n",
    "        path: path: path to digitStruct.mat\n",
    "        idx: index of the image\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # get image name and bounding info\n",
    "    name = get_img_name(f, idx)\n",
    "    boxes = get_img_boxes(f, idx)\n",
    "    \n",
    "    # get dimensions of image\n",
    "    try:\n",
    "        (h_img, w_img) = cv.imread(path + name).shape[:2]\n",
    "    except:\n",
    "        print(f\"ERROR: Could not open {name} to get dimensions.\")\n",
    "        print(\"Make sure image is in same directory as digitStruct.mat\")\n",
    "        print(f\"Tried:  {path + name}\")\n",
    "        \n",
    "    # initialize list for annotations\n",
    "    annots = []\n",
    "    \n",
    "    for i in range(len(boxes['label'])):\n",
    "        # get original bounding values\n",
    "        (x, y) = (boxes['left'][i], boxes['top'][i])\n",
    "        (w, h) = (boxes['width'][i], boxes['height'][i])\n",
    "\n",
    "        # transform x and y\n",
    "        centerX = x + (w / 2)\n",
    "        centerY = y + (h / 2)\n",
    "\n",
    "        # normalize bounding values\n",
    "        centerX /= w_img\n",
    "        centerY /= h_img\n",
    "        w /= w_img\n",
    "        h /= h_img\n",
    "\n",
    "        # get label\n",
    "        label = boxes['label'][i] if boxes['label'][i] != 10 else 0\n",
    "\n",
    "        # append annotation in Darknet format to annotation list\n",
    "        annots.append(f'{label} {centerX} {centerY} {w} {h}\\n' )\n",
    "    \n",
    "    # write annotations to file \n",
    "    annot_file = open(path + name.split('.')[0] + '.txt', 'w')\n",
    "    annot_file.writelines(annots)\n",
    "    annot_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optimum-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annot_files(path):\n",
    "    \"\"\"\n",
    "    Create Darknet TXT annotation file for all images in directory.\n",
    "    Writes to files <image name>.txt in same directory as images.\n",
    "\n",
    "    Args\n",
    "        path: path to digitStruct.mat\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if path[-1] != '/':\n",
    "        path += '/'\n",
    "    \n",
    "    try:\n",
    "        f = h5py.File(f'{path}digitStruct.mat', mode='r')\n",
    "    except:\n",
    "        print(\"ERROR: Could not open file.  Check path to digitStruct.mat\")\n",
    "        \n",
    "    for i in range(len(f['digitStruct/name'])):\n",
    "        create_annot_file(f, path, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-times",
   "metadata": {},
   "source": [
    "## Create Annotation Files\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation files for train data\n",
    "path = '../DATA/SVHN/Full/train'\n",
    "create_annot_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation files for test data\n",
    "path = '../DATA/SVHN/Full/test'\n",
    "create_annot_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "finished-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create annotation files for extra data\n",
    "path = '../DATA/SVHN/Full/extra'\n",
    "create_annot_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-support",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
