{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-queen",
   "metadata": {},
   "source": [
    "### Detector Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector:\n",
    "    \"\"\"\n",
    "    Create YOLO object detection model in OpenCV with a given config and weights.\n",
    "    Use this model to make predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg, wts, classes):\n",
    "        \n",
    "        self.classes = classes\n",
    "        self.net = cv.dnn.readNetFromDarknet(cfg, wts)\n",
    "        self.net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "        # determine the output layer\n",
    "        self.ln = self.net.getLayerNames()\n",
    "        self.ln = [self.ln[i[0] - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        \n",
    "    def detect(self, img, conf_thresh):\n",
    "        \n",
    "        #format image for detection\n",
    "        blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        \n",
    "         # get detections\n",
    "        self.net.setInput(blob)\n",
    "        outputs = self.net.forward(self.ln)\n",
    "\n",
    "        # initialize lists\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []\n",
    "\n",
    "        # initialize image dimensions\n",
    "        h_img, w_img = img.shape[:2]\n",
    "\n",
    "        for output in outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "\n",
    "                # drop low confidence detections and \n",
    "                if confidence > conf_thresh:\n",
    "                    box = detection[:4] * np.array([w_img, h_img, w_img, h_img])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    box = [x, y, int(width), int(height)]\n",
    "                    boxes.append(box)\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "\n",
    "        # apply non maximal suppression for\n",
    "        # initialize lists\n",
    "        self.boxes = []\n",
    "        self.confidences = []\n",
    "        self.detected_classes = []\n",
    "        cls_and_box = []\n",
    "        # get indices of final bounding boxes  \n",
    "        indices = cv.dnn.NMSBoxes(boxes, confidences, conf_thresh, 0.4)\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            for i in indices.flatten():\n",
    "                self.boxes.append(boxes[i])\n",
    "                self.confidences.append(confidences[i])\n",
    "                self.detected_classes.append(self.classes[classIDs[i]])\n",
    "                \n",
    "                cls_and_box.append([self.classes[classIDs[i]], boxes[i]])\n",
    "        \n",
    "        return cls_and_box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-exploration",
   "metadata": {},
   "source": [
    "### Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greater-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bib detection model config\n",
    "bd_configPath = '../Data/YOLO/bib_detector/RBNR1_custom-yolov4-tiny-detector.cfg'\n",
    "bd_weightsPath = '../Data/YOLO/bib_detector/RBNR1_custom-yolov4-tiny-detector_best.weights'\n",
    "bd_classes = ['bib']\n",
    "\n",
    "# Number reader config\n",
    "nr_configPath = '../Data/YOLO/num_reader/SVHN3_custom-yolov4-tiny-detector.cfg'\n",
    "nr_weightsPath = '../Data/YOLO/num_reader/SVHN3_custom-yolov4-tiny-detector_best.weights'\n",
    "nr_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Bib bounding box color\n",
    "color = [252, 15, 192]\n",
    "\n",
    "# Instantiate detectors\n",
    "bd = Detector(bd_configPath, bd_weightsPath, bd_classes)\n",
    "nr = Detector(nr_configPath, nr_weightsPath, nr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specified-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video feed\n",
    "cap = cv.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intermediate-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_times = []\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    # time prediction\n",
    "    start = time.time()\n",
    "    # Make predictions and mark image\n",
    "    bib_detections = bd.detect(img, 0.25)\n",
    "\n",
    "    for obj in bib_detections:\n",
    "        # crop out detected bib\n",
    "        (x, y, w, h) = obj[1]\n",
    "        crop_img = img[y:y+h, x:x+w]\n",
    "\n",
    "        # detect numbers on bib\n",
    "        num_detections = nr.detect(crop_img, 0.5)\n",
    "        bib_digit_loc = []\n",
    "        if len(num_detections) > 0:\n",
    "            # draw bouding box on original image\n",
    "            img = cv.rectangle(img,(x,y),(x+w,y+h),color,5)\n",
    "            # get digits and locations\n",
    "            for obj in num_detections:\n",
    "                (d_x, d_y, d_w, d_h) = obj[1]\n",
    "                bib_digit_loc.append((d_x, str(obj[0])))\n",
    "\n",
    "            # sort detected numbers L->R and put together\n",
    "            bib_digit_loc.sort()\n",
    "            rbn = int(''.join([i[1] for i in bib_digit_loc]))\n",
    "            # add bib number to original image\n",
    "            cv.putText(img, str(rbn), (x, y - 25), cv.FONT_HERSHEY_SIMPLEX, 2, color, 4)\n",
    "\n",
    "    end = time.time()\n",
    "    detection_times.append(end - start)\n",
    "    #print(f'Pred time: {round(end - start, 2)} seconds')\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame',img)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "composed-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04228322152017964"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(detection_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liable-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07722687721252441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(detection_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-trading",
   "metadata": {},
   "source": [
    "## Bib Detection Validation\n",
    "### Original\n",
    "![Bib Detection](../Data/Bib_detection_training_validation_orig.png \"Bib Detection\") \n",
    "### With Augmented Data\n",
    "![Bib Detection](../Data/Bib_detection_training_validation.png \"Bib Detection\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-surveillance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
